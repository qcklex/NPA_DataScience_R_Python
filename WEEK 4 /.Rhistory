library(tm)
print(my_file)
my_file = data.table::fread("answer gpt.txt", sep = "\n")
my_file = data.table::fread("answer gpt.txt", sep = "\n")
print(my_file)
library(tm)
NLP
install.package(NLP)
installed.packages(NLP)
library(tm)
library(tm)
my_file = data.table::fread("answer_gpt.txt", sep = "\n")
my_file = data.table::fread("answer_gpt.txt", sep = "\n")
install.packages("NLP")
install.packages("tm")
library(tm)
library(tm)
my_file = data.table::fread("answer_gpt.txt", sep = "\n")
install.packages("data.table")
my_file = data.table::fread("answer_gpt.txt", sep = "\n")
library(tm)
my_file = data.table::fread("answer_gpt.txt", sep = "\n")
install.packages("tm")
library(tm)
library(tm)
install.packages("tm")#
library(tm)
library(tm)
print(my_file)
my_file = data.table::fread("answer_gpt.txt", sep = "\n")
getwd()
getwd('/Users/whil/Desktop/DATA SCIENCE - NPA/WEEK 4 ')
'/Users/whil/Desktop/DATA SCIENCE - NPA/WEEK 4'
print(my_file)
print(my_file)
file.exists("answer_gpt.txt")
ls
list.files()
getwd()
setwd('/Users/whil/Desktop/DATA SCIENCE - NPA/WEEK 4 ')
setwd('/Users/whil/Desktop/DATA SCIENCE - NPA/WEEK 4')
getwd()
list.files()
file.exists("answer_gpt.txt")
print(my_file)
file.exists("answer_gpt.txt")
print(my_file)
install.packages("data.table")
library(data.table)
library(data.table)
library(data.table)
my_file = data.table::fread("answer_gpt.txt", sep = "\n")
print(my_file)
my_file = data.table::fread("answer_gpt.txt", sep = "\n")
print(my_file)
print(my_file)
print(my_file)
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
print(my_file)
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
txt <- PlainTextDocument(VectorSource(my_file))
txt <- PlainTextDocument(VectorSource(my_file))
library(tm)
library("NPM")
library(NPM)
library(tm)
txt <- PlainTextDocument(VectorSource(my_file))
x=termFreq(txt, control=list(tolower= T, removeNumbers = T, removePunctuation = T))
head(sort(x, decreasing=TRUE), 10)
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
txt <- PlainTextDocument(VectorSource(my_file))
x = termFreq(txt, control = list(tolower = T, removeNumbers = T,
removePunctuation = T))
head(sort(x, decreasing = TRUE), 10)
install.packages("devtools") # for dev tools
install.packages("tm") # for text mining
install.packages("SnowballC") # for text stemming
install.packages("wordcloud") # word-cloud generator
install.packages("wordcloud2") # word-cloud generator
install.packages("RColorBrewer") # color palettes
library("tm")
library("SnowballC")
library("wordcloud")
library("wordcloud2")
library("RColorBrewer")
text <- readLines ("C.:\\UserName\\Documents\\NPA_DS\\scotland.txt")
text <- readLines("C.:\\UserName\\Documents\\NPA_DS\\scotland.txt")
text <- readLines("/Users/whil/Desktop/DATA SCIENCE - NPA/WEEK 4 /scotland.txt")
docs <- Corpus(VectorSource(text))
docs <- tm_maps(docs, content_transformer(tolower))
library(tm)
docs <- tm_maps(docs, content_transformer(tolower))
install.packages("tm_maps")
docs <- tm_maps(docs, content_transformer(tolower))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- VCorpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, c("the", "this", "said", "like", "now",
"went","come"))
docs <- tm_map(docs, removeWords, c("the", "this", "said", "like", "now","went","come"))
docs <- tm_maps(docs, removePunctuation)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <0 tm_map(docs, stemDocument)
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing=TRUE)
d <- data.frame(word = names(v), freq=v
)
head(d,10)
set.seed(1234)
findFreqTerms(dtm, lowfreq = 4)
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
col ="lightgreen", main ="Most frequent words",
ylab = "Word frequencies")
wordcloud2(demoFreq, color = "random-light", backgroundColor = "grey")
wordcloud(words = d$word, rot.per=.5, max.words = 200,
min.freq = 5, scale=c(4,.5))
wordcloud(words = d$word, rot.per=.5, max.words = 200,
min.freq = 5, scale=c(4,.5))
source("~/Desktop/DATA SCIENCE - NPA/WEEK 4 /text_script.R")
install.packages("devtools") # for dev tools
install.packages("tm") # for text mining
install.packages("SnowballC") # for text stemming
install.packages("wordcloud") # word-cloud generator
install.packages("wordcloud2") # word-cloud generator
install.packages("RColorBrewer") # color palettes
library("tm")
library("SnowballC")
library("wordcloud")
library("wordcloud2")
library("RColorBrewer")
text <- readLines("/Users/whil/Desktop/DATA SCIENCE - NPA/WEEK 4 /Article.txt")
docs <- VCorpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, c("the", "this", "said", "like", "now","went","come"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud2(demoFreq, color = "random-light", backgroundColor = "grey")
wordcloud2(demoFreq, color = "random-light", backgroundColor = "grey")
wordcloud2(demoFreq, color = "random-light", backgroundColor = "grey")
wordcloud2(demoFreq, color = "random-light", backgroundColor = "grey")
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
require(devtools)
install_github("lchiffon/wordcloud2")
install("wordcloud23")
install("wordcloud22")
install("wordcloud2")
library(wordcloud2)
wordcloud2(df, size = 1)
text_data <- readLines("Article.txt")
wordcloud2(demoFreq, color = "random-light", backgroundColor = "grey")
wordcloud2( color = "random-light", backgroundColor = "grey")
wordcloud2(color = "random-light", backgroundColor = "grey")
wordcloud2(df, size1)
wordcloud2(df, size=1)
library(wordcloud2)
library(tm)
library(readr)
install.packages("readr")
library(wordcloud2)
library(tm)
library(readr)
text_data <- readLines("Article", warn = FALSE)
corpus <- Corpus(VectorSource(text_data))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
df <- data.frame(word = names(word_freqs), freq = as.numeric(word_freqs))  # Convert correctly
wordcloud2(df, size = 1)
wordcloud2(df, size = 4)
library(wordcloud2)
library(tm)
library(readr)
text_data <- readLines("yourfile.txt", warn = FALSE)
getdw()
getwd
getwd()
list.files()
file.remove(Article)
file.remove(Article)
file.remove("Article")
getwd()
list.files()
wordcloud2(demoFreq, color = "random-light", backgroundColor = "grey")
> docs <- tm_map(docs, stemDocument)
wordcloud(words = d$word, freq = d$freq, min.freq = 15,
max.words=50, random.order=FALSE, rot.per=0.5,
colors=brewer.pal(9, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 15,
max.words=50, random.order=FALSE, rot.per=0.5,
colors=brewer.pal(8, "Dark2"))
library("tm")
library("SnowballC")
library("wordcloud")
library("wordcloud2")
library("RColorBrewer")
text <- readLines("Article.txt")
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(tolower))
> text <- readLines("Article.txt")
text <- readLines("Article.txt")
docs <- VCorpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, c("the", "this", "said", "like", "now", "went","come"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 50)
> docs <- tm_map(docs, removeWords, c("and"))
docs <- tm_map(docs, removeWords, c("and"))
head(d, 50)
set.seed(1234)
wordcloud(words = d$word, rot.per=.5, max.words = 200, min.freq = 5, scale=c(4,.5))
wordcloud(words = d$word, freq = d$freq, min.freq = 15,
max.words=50, random.order=FALSE, rot.per=0.5,
colors=brewer.pal(9, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 15, max.words=50, random.order=FALSE, rot.per=0.5, colors=brewer.pal(9, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 15, max.words=50, random.order=FALSE, rot.per=0.5, colors=brewer.pal(5, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 15, max.words=50, random.order=FALSE, rot.per=0.5, random.color = TRUE )
wordcloud(words = d$word, freq = d$freq, min.freq = 15, max.words=50, random.order=FALSE, rot.per=0.5, random.color = TRUE )
wordcloud(words = d$word, freq = d$freq, min.freq = 15,
max.words=50, random.order=FALSE, rot.per=0.5,
colors=brewer.pal(9, "Dark2"))
wordcloud(words = d$word, rot.per=.5, max.words = 200,
min.freq = 5, scale=c(4,.5))
wordcloud(words = d$word, min.freq = 5, rot.per=.5, max.words = 200,
min.freq = 5, scale=c(4,.5))
wordcloud(words = d$word, min.freq = 5, rot.per=.5, max.words = 200,
min.freq = 5, scale=c(4,.5))
wordcloud(words = d$word, min.freq = 5, rot.per=.5, max.words = 200,
min.freq = 5, scale=c(4,.5))
wordcloud(words = d$word, rot.per=.5, max.words = 200,
min.freq = 5, scale=c(4,.5))
warnings()
wordcloud(words = d$word, rot.per=.5, max.words = 200,
min.freq = 5, scale=c(4,.5), random.color = TRUE)
prepositions <- c("in", "on", "at", "since", "for", "ago", "before", "to",
"past", "until", "by", "next", "from", "over", "under",
"between", "into", "through", "during", "with", "without",
"against", "among", "around", "about", "as", "like",
"and", "that")
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), prepositions))
wordcloud(words = d$word, rot.per=.5, max.words = 200,
min.freq = 5, scale=c(4,.5))
par(bg = "pink")
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 5,
scale = c(4, 0.5),
colors = sample(colors(), length(d$word)))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 0.5),
colors = sample(colors(), length(d$word)))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1),
colors = sample(colors(), length(d$word)))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 3),
colors = sample(colors(), length(d$word)))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(colors(), length(d$word)))
prepositions <- c("in", "on", "at", "since", "for", "ago", "before", "to",
"past", "until", "by", "next", "from", "over", "under",
"between", "into", "through", "during", "with", "without",
"against", "among", "around", "about", "as", "like",
"and", "that")
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), prepositions))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(colors(), length(d$word)))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(colors(), length(d$word)))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(colors(), length(d$word)))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(colors(), length(d$word)))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(colors(), length(d$word)))
docs <- tm_map(docs, removeWords, c("and", "with", "that"))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(colors(), length(d$word)))
docs <- tm_map(docs, removeWords, c("and", "with", "that"))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(colors(blue), length(d$word)))
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(colors(), length(d$word)))
blue_shades <- c("#1E90FF", "#4682B4", "#5F9EA0", "#87CEFA", "#6495ED", "#00BFFF", "#4169E1")
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(blue_shades, length(d$word), replace = TRUE))  # Random blue shades
)
wordcloud(words = d$word,
freq = d$freq,
rot.per = 0.5,
max.words = 200,
min.freq = 1,
scale = c(4, 1.2),
colors = sample(blue_shades, length(d$word), replace = TRUE))
wordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "pink",
shape = "circle")
docs <- tm_map(doc, removeWords, c("and", "with", "that"))
docs <- tm_map(docs, removeWord, "and")
docs <- tm_map(docs, removeWord, c("and"))
docs <- tm_map(doc, removeWords, ("and", "with", "that"))
docs <- tm_map(doc, removeWords, c("and", "with", "that"))
docs <- tm_map(docs, removeWords, c("and", "with", "that"))
docs <- tm_map(docs, removeWords, c("and"))
wordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "pink",
shape = "circle")
d <- d[!d$word %in% c("and"), ]
wordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "pink",
shape = "circle")
d <- d[!d$word %in% c("with"), ]
wordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "pink",
shape = "circle")
wordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "pink",
shape = "circle")
text <- readLines("/Users/whil/Desktop/DATA SCIENCE - NPA/WEEK 4 /exercise2_gpt.txt")
text <- readLines("exercise2_gpt.txt")
text <- readLines("exercise2_gpt.txt")
text <- readLines("exercise2_gpt.txt")
text <- readLines("exercise2_gpt.txt")
text <- readLines("exercise2_gpt.txt")
docs <- VCorpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, c("the", "this", "said", "like", "now",
"went","come"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
d <- d[!d$word %in% c("and"), ]  # Remove "and"
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
d <- d[!d$word %in% c("and"), ]  # Remove "and"
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
par(bg = "yellowwordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "lightyellow",
par(bg = "yellowwordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "lightyellow",
wordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "lightyellow",
shape = "circle")
d <- d[!d$word %in% c("and"), ]
wordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "lightyellow",
shape = "circle")
install.packages("textstem")
library(textstem)
text <- readLines("exercise2_gpt.txt")
docs <- tm_map(docs, lemmatize_strings)
wordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "lightyellow",
shape = "circle")
docs <- VCorpus(VectorSource(readLines("exercise2_gpt.txt", warn = FALSE)))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("en"))
> docs <- tm_map(docs, removeWords, c("the", "this", "said", "like", "now", "and", "that"
docs <- tm_map(docs, removeWords, c("the", "this", "said", "like", "now", "and", "that","went","come"))
wordcloud2(d,
size = 1,
color = sample(blue_shades, nrow(d), replace = TRUE),
backgroundColor = "lightyellow",
shape = "circle")
